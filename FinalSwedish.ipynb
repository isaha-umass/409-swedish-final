{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9aad2a9-6c4c-497a-874c-7aaafbf49bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Necessary Libraries\n",
    "import conllu\n",
    "import random\n",
    "random.seed(123)\n",
    "import math\n",
    "import gensim.downloader as gensim_api\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import stats\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826a0d3-9f2f-479d-aa97-77121bdc26ad",
   "metadata": {},
   "source": [
    "# Task 1.2: English Syntax Generalization Practice\n",
    "We used the English GUM corpus with 233k entries maintained by Georgetown University Linguistics students. The text comes from multiple media formats. Our goal was to examine a generalization on verbs and their direct object pronouns within the corpus. The generalization accurately described the relevant sentences in the corpus.\n",
    "\n",
    "## Our Generalization\n",
    "**Expected Generalization:** Pronoun direct objects immediately follow their linked verbs.\n",
    "\n",
    "An example that illustrates this generalization is provided below.\n",
    "\n",
    "“First, our experimental subjects lived in a large enclosure under conditions that **allowed them** to exercise all day long.”\n",
    "\n",
    "## Results\n",
    "We used a function called 'finderskeepers' to search the corpus for sentences that contain pronoun (direct) objects linked to verbs. If those pronouns immediately followed the verb, then they fit our generalization. Otherwise, they were flagged as exceptions.\n",
    "\n",
    "About 86% of the corpus fit our generalization; direct object pronouns indeed follow their linked verbs. The exceptions to this are when adverbs modify the verb, adjectives modify the pronoun, wh-questions, a passivized verb requires argument movement to bring the direct object pronoun *forward* in the sentence, among others. Examples are provided below.\n",
    "\n",
    "## Examples of Exceptions\n",
    "### Wh-Question\n",
    "\"If your professor comes into an early morning class holding a mug of liquid, **what** do you assume she is **drinking**?\"\n",
    "\n",
    "### Stammer\n",
    "“You know, **documenting**, uh, uh, **whatever**.”\n",
    "\n",
    "### Modifying Preposition\n",
    "\"And I said ‘Ben, **pick** me out **something**, you've got fifty bucks to spend.'\"\n",
    "\n",
    "### Dialogue\n",
    "\"Whitmore told LA Weekly that on October 6 after traveling back from Florida, Montalvo ‘walked into lobby of the East L.A. station and turned himself in’, and **told** the police, ‘**everything** he did’.”\n",
    "\n",
    "### Wh-Movement\n",
    "“Malaysia and Indonesia have maintained a policy of turning away boats of migrants **which**, according to AFP, the United Nations and United States have both **criticised**.”\n",
    "\n",
    "### Movement\n",
    "\"**This** I would have **asked** him had he not been so far away, but he was very far, and could not be seen at all when he drew nigh that gigantic reef.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37fd1d24-4fd6-4368-b802-8eff3defc6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def englishGen(sentences, sample_size):\n",
    "    fit_generalization = []\n",
    "    possible_exceptions = []\n",
    "    current = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word[\"upos\"] == \"PRON\" and word[\"deprel\"] == \"obj\": # and word[\"lemma\"] != \"that\"\n",
    "                if word[\"head\"] != None and sentence[word[\"head\"]-1][\"upos\"] == \"VERB\":\n",
    "                    current[\"sentence\"] = sentence.metadata['text']\n",
    "                    current[\"PRON\"] = word\n",
    "                    current[\"VERB\"] = sentence[word[\"head\"]-1]\n",
    "                    if word[\"id\"] != 0 and word[\"id\"]-1 == word[\"head\"]:\n",
    "                        if current not in fit_generalization:\n",
    "                            fit_generalization.append(current.copy())\n",
    "                    elif word[\"id\"]-1 != word[\"head\"]: # != gets all possible exceptions\n",
    "                        if current not in possible_exceptions:\n",
    "                            possible_exceptions.append(current.copy())\n",
    "    \n",
    "    print(f\"Sentences that fit the generalization: {len(fit_generalization)}\\n\")\n",
    "    \n",
    "    fitted_samples = random.sample(fit_generalization, sample_size)\n",
    "    \n",
    "    for entry in fitted_samples:\n",
    "        print(f'PRON: {entry[\"PRON\"]}, VERB: {entry[\"VERB\"]}\\n Sentence: {entry[\"sentence\"]}\\n')\n",
    "    \n",
    "    print(f\"\\nSentences that may (or may not) be exceptions: {len(possible_exceptions)}\\n\")\n",
    "    \n",
    "    fitted_samples = random.sample(possible_exceptions, sample_size)\n",
    "    \n",
    "    for entry in fitted_samples:\n",
    "        print(f'PRON: {entry[\"PRON\"]}, VERB: {entry[\"VERB\"]}\\n Sentence: {entry[\"sentence\"]}\\n')\n",
    "    \n",
    "    #print(count)\n",
    "    print(f\"\\nTotal sentences with Pronouns linked to Verbs: {len(fit_generalization)+len(possible_exceptions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "208ec308-661c-4eb3-aa8f-8413eae22337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences that fit the generalization: 995\n",
      "\n",
      "PRON: something, VERB: putting\n",
      " Sentence: Putting, putting something out there, getting it smashed down in front of everyone, and then immediately, like having to jump back up and like, do it again.\n",
      "\n",
      "PRON: it, VERB: started\n",
      " Sentence: \"They started it.\"\n",
      "\n",
      "PRON: herself, VERB: picking\n",
      " Sentence: Jenna was picking herself up off the floor of the bathroom.\n",
      "\n",
      "PRON: it, VERB: making\n",
      " Sentence: Birkholm Is only 1km² and home of a stubborn but loving 8 people, making it one of the smallest populated islands in the country, how long the island can sustain a full year population remains to be seen, but permanent life on the island will probably be a thing of the past in a not too distant future.\n",
      "\n",
      "PRON: it, VERB: like\n",
      " Sentence: And I really like it.\n",
      "\n",
      "\n",
      "Sentences that may (or may not) be exceptions: 156\n",
      "\n",
      "PRON: what, VERB: do\n",
      " Sentence: How were the plaintiffs supposed to -- what were they supposed to do when the notice gave no notice whatsoever, as to how they were supposed to, what would happen to their property if it was confiscated?\n",
      "\n",
      "PRON: that, VERB: say\n",
      " Sentence: The best that the experts could say was that they agreed that the fire started in the northeast quadrant of the living room.\n",
      "\n",
      "PRON: everything, VERB: told\n",
      " Sentence: Whitmore told LA Weekly that on October 6 after traveling back from Florida, Montalvo \"walked into lobby of the East L.A. station and turned himself in\", and told the police, \"everything he did\".\n",
      "\n",
      "PRON: what, VERB: gon\n",
      " Sentence: I'm like \"oh my god, what am I gonna tell my mom? I can't be a mom.\"\n",
      "\n",
      "PRON: which, VERB: criticised\n",
      " Sentence: Malaysia and Indonesia have maintained a policy of turning away boats of migrants which, according to AFP, the Untied Nations and United States have both criticised.\n",
      "\n",
      "\n",
      "Total sentences with Pronouns linked to Verbs: 1151\n"
     ]
    }
   ],
   "source": [
    "with open(\"en_gum-ud-train.conllu\", encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "sentences_english = conllu.parse(data)\n",
    "englishGen(sentences_english, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe8f16-3a67-4a20-ba59-53715ccac564",
   "metadata": {},
   "source": [
    "# Tasks 1.1 & 1.3: Swedish Verb Negation Generalization\n",
    "We used the Swedish LinES corpus (from the Parallel Treebank of the same name) that includes just over 100k Swedish translations from English text. Our goal was to examine a generalization on Swedish verb negation. Our results conflicted with our expectations, and so we performed further examination to search for a different possible generalization.\n",
    "\n",
    "## Our Generalization\n",
    "**Expectated Generalization:** Negation words immediately follow the verb they negate.\n",
    "\n",
    "The below example illustrates this generalization. \n",
    "\n",
    "“Hon **svarade inte**.”\n",
    "(She didn't answer.)\n",
    "('inte' = 'not', linked words are bolded)\n",
    "\n",
    "## Results & Discussion\n",
    "We used a function called 'swedishchecker' to search the corpus for negation words linked to verbs. Then we filtered instances where the negation came immediately after the verb; those examples fit our generalization. The other sentences were cached as exceptions.\n",
    "\n",
    "Only about 21% of our corpus fit the expected generalization. There were a lot of exceptions ranging from embedded sentences, questions, auxiliaries, verb-object switches, and the list goes on. Some examples of these are provided below:\n",
    "\n",
    "\n",
    "## Secondary Corpus Test\n",
    "When tested with a slightly smaller corpus (96k entries) called Talbanken from Lund University. The sentences were taken from various text genres like textbooks, brochures, and newspaper articles. We found similar results to the above, where 22% of the sentences with negated verbs actually fit our generalization. This leads us to believe that the translation bias in our first corpus may not be the reason that our generalization fits so poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "461c20ea-b84d-4b3d-b155-c756891cd2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swedishGen(sentences, sample_size):\n",
    "    fit_generalization = []\n",
    "    possible_exceptions = []\n",
    "    current = {}\n",
    "    exceptions = []\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word[\"xpos\"] == \"NEG\" and word[\"head\"] != None and sentence[word[\"head\"]-1][\"upos\"] == \"VERB\":\n",
    "            #if word[\"feats\"] != None and \"Polarity\" in word[\"feats\"].keys() and word[\"feats\"][\"Polarity\"] == \"Neg\" and and word[\"head\"] != None and sentence[word[\"head\"]-1][\"upos\"] == \"VERB\": # xpos \"NEG\", upos --\n",
    "                current[\"sentence\"] = sentence.metadata['text']\n",
    "                try:\n",
    "                    current[\"sentence-E\"] = sentence.metadata['text_en']\n",
    "                except:\n",
    "                    current[\"sentence-E\"] = None\n",
    "                current[\"NEG\"] = word\n",
    "                current[\"VERB\"] = sentence[word[\"head\"]-1]\n",
    "                if word[\"id\"] != 0 and word[\"id\"]-1 == word[\"head\"]:\n",
    "                    if current not in fit_generalization:\n",
    "                        fit_generalization.append(current.copy())\n",
    "                elif word[\"id\"]-1 != word[\"head\"]:\n",
    "                    if current not in possible_exceptions:\n",
    "                        possible_exceptions.append(current.copy())\n",
    "                        exceptions.append(sentence)\n",
    "                            \n",
    "    print(f\"Sentences that fit the generalization: {len(fit_generalization)}\\n\")\n",
    "    fitted_samples = random.sample(fit_generalization, min(sample_size, len(fit_generalization)))\n",
    "    for entry in fitted_samples:\n",
    "        print(f'NEG: {entry[\"NEG\"]}, VERB: {entry[\"VERB\"]}\\n'\n",
    "              f'Sentence: {entry[\"sentence\"]}\\n'\n",
    "              f'English Translation: {entry[\"sentence-E\"]}\\n')\n",
    "\n",
    "    print(f\"\\nSentences that may (or may not) be exceptions: {len(possible_exceptions)}\\n\")\n",
    "    fitted_samples = random.sample(possible_exceptions, min(sample_size, len(possible_exceptions)))\n",
    "    for entry in fitted_samples:\n",
    "        print(f'NEG: {entry[\"NEG\"]}, VERB: {entry[\"VERB\"]}\\n'\n",
    "              f'Sentence: {entry[\"sentence\"]}\\n'\n",
    "              f'English Translation: {entry[\"sentence-E\"]}\\n')\n",
    "\n",
    "    return exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b27d93c1-9e49-43df-8d96-c0a23dd108ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences that fit the generalization: 99\n",
      "\n",
      "NEG: inte, VERB: ansågs\n",
      "Sentence: Detta ansågs inte speciellt egendomligt: andra amerikanska ambassadörer och ministrar i arabvärlden stödde helhjärtat \"äkta\" revolutioner för att störta gamla jordägare, rika skurkar och politiker.\n",
      "English Translation: This was not considered particularly bizarre; other American ambassadors and ministers in the Arab world were entirely in favor of \"genuine\" revolution to overthrow old landowners, rich crooks, and politicians.\n",
      "\n",
      "NEG: inte, VERB: finns\n",
      "Sentence: Man kan på datorn få ut en piratversion, men den finns inte på franska.\n",
      "English Translation: A pirate electronic version is available but not in French.\n",
      "\n",
      "NEG: inte, VERB: gick\n",
      "Sentence: Den gick inte att äta.\n",
      "English Translation: This was not for eating.\n",
      "\n",
      "NEG: inte, VERB: uppfattade\n",
      "Sentence: Vem var det? Jag vet inte... en av passagerarna i planet... en lätt flintskallig, blond karl med främmande brytning, jag uppfattade inte namnet.\n",
      "English Translation: Who was that I don't know... one of the people from the plane... a baldish fair man with an accent, I didn't catch the name.\n",
      "\n",
      "NEG: inte, VERB: talar\n",
      "Sentence: \"Hon talar inte jiddisch?\"\n",
      "English Translation: \"She doesn't speak Yiddish?\"\n",
      "\n",
      "\n",
      "Sentences that may (or may not) be exceptions: 368\n",
      "\n",
      "NEG: inte, VERB: låta\n",
      "Sentence: Du sa alldeles nyss att man inte borde låta sig tyngas av lidanden.\n",
      "English Translation: You've just said one shouldn't burden oneself with suffering.\n",
      "\n",
      "NEG: inte, VERB: skyddat\n",
      "Sentence: Det innebär att en användare med en lämplig licens kan göra ändringar av informationen i ett kalkylblad, ändra formateringen, dra fält i ett diagram eller en pivottabellista osv, under förutsättning att du inte har skyddat de här alternativen när du utvecklade sidan.\n",
      "English Translation: That is, a user with an appropriate license can make changes to data in a spreadsheet, change formatting, drag fields in a chart or PivotTable List, and so on, as long as you didn't protect these options at design time.\n",
      "\n",
      "NEG: inte, VERB: göra\n",
      "Sentence: Och särskilt när man hävdar att motorerna är miljövänliga eftersom de förbrukar mindre bränsle kan man inte göra några undantag.\n",
      "English Translation: It is precisely when engines are claimed to be environment-friendly because they consume less fuel that we can not make any exceptions.\n",
      "\n",
      "NEG: inte, VERB: följer\n",
      "Sentence: Herr Martin, jag ber er att besvara frågan utan att gå in i några diskussioner, eftersom detta inte följer arbetsordningen.\n",
      "English Translation: Mr Martin, please reply without engaging in a dialogue, as the Rules do not provide for one.\n",
      "\n",
      "NEG: aldrig, VERB: tänkas\n",
      "Sentence: Allt han kunde se var att han stod i en öppen murad spis i något som såg ut som en stor, svagt upplyst trollkarlsbutik – men sakerna här inne kunde nog aldrig tänkas stå på Hogwarts skollista.\n",
      "English Translation: All he could tell was that he was standing in the stone fireplace of what looked like a large, dimly lit wizard's shop – but nothing in here was ever likely to be on a Hogwarts school list.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"sv_lines-ud-train.conllu\", encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "sentences_swedish = conllu.parse(data)\n",
    "exceptions = swedishGen(sentences_swedish,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951918d9-ef2e-4dd5-8ba2-1848f7ccf61a",
   "metadata": {},
   "source": [
    "# Generalization Exceptions\n",
    "Our generalization seems to hold on simple sentences with little to no nuance.\n",
    "\n",
    " Examples include:\n",
    "\n",
    "“Hon svarade inte.” -“She didn't answer.”\n",
    "\n",
    "\"Hon talar inte jiddisch?\" - “She doesn't speak Yiddish?”\n",
    "\n",
    "These sentences relay straightforward information and do not contain many flourishes in speech. If we were to only consider such sentencs, our generalization holds with 21% accuracy on verb negations.\n",
    "\n",
    "However, if we take into account more detailed sentences, we see a diffrerent result. In examining our initial results, there were two main exceptions we identified that change the location of negation. If we include this nuance, accuracy increases to 44%\n",
    "\n",
    "- **Auxiliary verbs:** if auxilary verbs are present, the negation is placed between the auxiliary and the main (head) verb\n",
    "\n",
    "“Hans sekreterare hade inte ringt det samtal hon hade fått instruktioner om.”\n",
    "\n",
    "“His secretary had not made the instructed call.”\n",
    "\t\n",
    "- **Embedded clauses:** if there is an embedded clause, the negation follows the subject of the clause and preceedes the main (head) verb. This seems to happen because of rules regarding VPs in Swedish\n",
    "\n",
    "“Jag har suttit här tålmodigt och jag finner det anmärkningsvärt att ni inte ropar upp mig.”\n",
    "\n",
    "“I have sat here patiently and I find it quite extraordinary that you are not calling me.”\n",
    "\n",
    "While 44% accuracy might seem low, this result can be explained by recognizing a feature of Swedish that lets words be reordered to put emphasis on certain aspects of the sentence. For example, Object Shift allows for the object of a verb to swap places with the negation, while still producing a gramatical sentence\n",
    "\n",
    "“Jag förstår det inte alls.”\n",
    "\n",
    "“I do not understand it at all.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20304a7c-b775-4794-b0ce-c505f2e92986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute into swedishGen for Aux checking\n",
    "            if word[\"upos\"] == \"AUX\" and word[\"head\"] is not None:\n",
    "                head_idx = word[\"head\"] - 1\n",
    "                if sentence[head_idx][\"upos\"] == \"VERB\":\n",
    "\n",
    "                    if word[\"id\"] < len(sentence) and sentence[word[\"id\"]][\"xpos\"] == \"NEG\":\n",
    "                        current = {}\n",
    "                        current[\"sentence\"] = sentence.metadata.get(\"text\")\n",
    "                        try:\n",
    "                            current[\"sentence-E\"] = sentence.metadata[\"text_en\"]\n",
    "                        except KeyError:\n",
    "                            current[\"sentence-E\"] = sentence.metadata.get(\"Text_en\", None)\n",
    "\n",
    "                        current[\"AUX\"] = word\n",
    "                        current[\"NEG\"] = sentence[word[\"id\"]] \n",
    "                        current[\"VERB\"] = sentence[head_idx]\n",
    "\n",
    "                        if word[\"id\"] - 1 <= word[\"head\"]:\n",
    "                            if current not in fit_generalization:\n",
    "                                fit_generalization.append(current.copy())\n",
    "                        elif word[\"id\"] - 1 != word[\"head\"]:\n",
    "                            if current not in possible_exceptions:\n",
    "                                possible_exceptions.append(current.copy())\n",
    "                                exceptions.append(sentence)\n",
    "            if word[\"xpos\"] == \"NEG\":\n",
    "                if word[\"head\"] != None and sentence[word[\"head\"]-1][\"upos\"] == \"VERB\":\n",
    "                    current[\"sentence\"] = sentence.metadata['text']\n",
    "                    try:\n",
    "                        current[\"sentence-E\"] = sentence.metadata['text_en']\n",
    "                    except:\n",
    "                        try:\n",
    "                            current[\"sentence-E\"] = sentence.metadata['Text_en']\n",
    "                        except:\n",
    "                            print(f\"Error for sentence: {sentence.metadata}\")\n",
    "                            current[\"sentence-E\"] = None\n",
    "                    current[\"NEG\"] = word\n",
    "                    current[\"VERB\"] = sentence[word[\"head\"]-1]\n",
    "                    current[\"AUX\"] = None\n",
    "                    if word[\"id\"] != 0 and word[\"id\"]-1 >= word[\"head\"]:\n",
    "                        if current not in fit_generalization:\n",
    "                            fit_generalization.append(current.copy())\n",
    "                    elif word[\"id\"]-1 != word[\"head\"]:\n",
    "                        if current not in possible_exceptions:\n",
    "                            possible_exceptions.append(current.copy())\n",
    "                            exceptions.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b0c37-75ae-4370-bd76-ac58759009a8",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Verb Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10cae1e7-7f7d-4634-92cf-d5d61cc42419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verb_frequencies method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b96354d-2062-4ad6-a4bf-47a14be64d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_frequencies(sentences_swedish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f39d0-5ef5-49f6-ba62-af63cc8e7ad3",
   "metadata": {},
   "source": [
    "The verbs chosen are randomly sampled from the top 20% of verbs when sorted by frequency and the next 20% of most frequently used verbs -- five from each category. Frequency was determined by tallying the lemmas of each verb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3e737-9114-4133-bb63-198a95f09306",
   "metadata": {},
   "source": [
    "## Verb Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2659514-de87-4ef7-856c-67abbf5049c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sets(sentences, verb):\n",
    "    sets = {\"verb\": verb, \"subjects\": set(), \"objects\": set(), \"modifiers\": set(), \"before\": set(), \"after\": set()}\n",
    "    for sentence in sentences:\n",
    "        words = [x['lemma'] for x in sentence]\n",
    "        if (verb in words):\n",
    "            word_id = words.index(verb)+1\n",
    "            sets[\"before\"].add(words[word_id-2])\n",
    "            sets[\"after\"].add(words[word_id])\n",
    "            for word in sentence:\n",
    "                if(word[\"deprel\"] in [\"obj\", \"nsubj\", \"iobj\", \"advmod\"] and word[\"head\"] == word_id):\n",
    "                    match word[\"deprel\"]:\n",
    "                        case \"obj\" | \"iobj\":\n",
    "                            sets[\"objects\"].add(word[\"lemma\"])\n",
    "                        case \"nsubj\":\n",
    "                            sets[\"subjects\"].add(word[\"lemma\"])\n",
    "                        case \"advmod\":\n",
    "                            sets[\"modifiers\"].add(word[\"lemma\"])\n",
    "                    \n",
    "    return sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e590f-584b-4192-9140-87fda42894ae",
   "metadata": {},
   "source": [
    "For any verb's *lemma* in the set of Swedish sentences, this method generates a dictionary containing sets of each subjects, objects, modifiers, preceding words, and following words corresponding to the given verb. The set of modifiers for the verb only contains adverbs, (or those with the dependency relationship \"advmod\" to the verb), but not other modifiers like negation, prepositions, or auxiliaries. Including would have likely skewed our results by adding more noise, since semantically, adverbs might be more significant. However, it may have been beneficial to have include other modifiers as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30044b49-804b-4398-97cf-74a04a285a50",
   "metadata": {},
   "source": [
    "## Word 2 Vector Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f8ca3-2d3c-4c89-9288-127cf830bf49",
   "metadata": {},
   "source": [
    "After we have the sets of words that we need, we need to make the Word2Vec model. This is what the following function does, returning it in the form of a space so that we can use gensim library functions on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb9878a-c409-4b1e-8c51-061d92f294a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the word2vec model\n",
    "def make_W2V(conllu_corpus):\n",
    "    sentences = []\n",
    "    for tokList in conllu_corpus:\n",
    "        sent = []\n",
    "        for token in tokList:\n",
    "            if token != \"metadata\":\n",
    "                sent.append(token[\"lemma\"])\n",
    "        sentences.append(sent)\n",
    "        \n",
    "    space = Word2Vec(sentences, epochs=10, min_count=10, vector_size=300, sg = 1)\n",
    "    return space.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee89fb-91f8-448f-9bc4-5814f647ddfc",
   "metadata": {},
   "source": [
    "Now that we have the Word2Vec, we can compute the k nearest words semantically from the Word2Vec vectors. We can also find the centroid of each set by summing all of the word vectors in the set and finding the most similar vector to the sum. Note that the similarity is done via cosine similarity, so we do not need to divide the sum by the number of words (which would give the average vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5414b46f-5f51-4185-a3fe-2c50aa0b6255",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_sets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m reduce(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x \u001b[38;5;241m+\u001b[39m y, total)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m space\u001b[38;5;241m.\u001b[39msimilar_by_vector(\u001b[38;5;28msum\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m sets \u001b[38;5;241m=\u001b[39m gen_sets(sentences_swedish, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m space \u001b[38;5;241m=\u001b[39m make_W2V(sentences_swedish)\n\u001b[0;32m     14\u001b[0m centroid \u001b[38;5;241m=\u001b[39m find_centroid(sets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubjects\u001b[39m\u001b[38;5;124m\"\u001b[39m], space)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gen_sets' is not defined"
     ]
    }
   ],
   "source": [
    "def k_nearest(k, space, vector):\n",
    "    return space.most_similar(vector)[:k]\n",
    "\n",
    "def find_centroid(set: set, space):\n",
    "    total = []\n",
    "    for token in set:\n",
    "        total.append(space[token])\n",
    "    \n",
    "    sum = reduce(lambda x, y: x + y, total)\n",
    "    return space.similar_by_vector(sum)[0]\n",
    "\n",
    "sets = gen_sets(sentences_swedish, \"heta\")\n",
    "space = make_W2V(sentences_swedish)\n",
    "centroid = find_centroid(sets[\"subjects\"], space)\n",
    "k_nearest(5, space, centroid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848e5a2-e887-4d00-9cae-012819e96b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
